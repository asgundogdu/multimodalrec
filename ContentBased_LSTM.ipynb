{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from multimodalrec.multimodalrec import MultimodalRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multimodalrec.multimodalrec import data_pipeline\n",
    "from multimodalrec.model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multimodalrec.lossTypes import RMSELossGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recmodel = MultimodalRec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training User-Movie Latent Factors are extracting...\n",
      "The sparsity level of training dataset is 95.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 188/2930 [00:00<00:01, 1874.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Visual Representations are extracting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2930/2930 [00:01<00:00, 2191.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recmodel.organize_multimodal_data(load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.user_item_network_training.CF_data, self.user_latent_traninig, \n",
    "# self.visual_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recmodel.user_latent_traninig.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recmodel.visual_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_training = recmodel.user_item_network_training.CF_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "# Create X_train y_train (POSITIVE)\n",
    "pos_ratings_df = ratings_df_training[ratings_df_training.Rating>4]\n",
    "pos_ratings_df = pos_ratings_df.assign(Likes= lambda x: 1)\n",
    "\n",
    "# Create X_train y_train (NEGATIVE)\n",
    "neg_ratings_df = ratings_df_training[ratings_df_training.Rating<3]\n",
    "neg_ratings_df = neg_ratings_df.assign(Likes= lambda x: -1)\n",
    "\n",
    "training_df = pd.concat([pos_ratings_df,neg_ratings_df],axis=0)\n",
    "training_df = training_df.drop(['Timestamp','Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample num: 194425, Negative sample num: 131124\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive sample num: {}, Negative sample num: {}\".format(pos_ratings_df.shape[0],neg_ratings_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes\n",
    "batch_size_ = 64\n",
    "eopch_num = 10000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1_frames = 30\n",
    "input_1_dimension = 2048\n",
    "hidden_size = 16\n",
    "input_2_dimension = 256\n",
    "batch_size = 64\n",
    "is_training = True\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.name_scope('main_parameters'):\n",
    "    x_lstm = tf.placeholder(tf.float32, [None, input_1_frames, input_1_dimension], name='Input_LSTM')\n",
    "    x_lstm_seq_length = tf.placeholder(tf.int32, [None], name='Input_LSTM_Seq_lenght')\n",
    "    x_lstm_keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    x_fusion = tf.placeholder(tf.float32, shape=[None, input_2_dimension], name='Input_fusion')\n",
    "    \n",
    "    y = tf.placeholder(tf.float32, shape=[None, 1], name='Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('lstm_layer') as scope:\n",
    "    seq_flat = tf.reshape(x_lstm, [-1, input_2_dimension])\n",
    "    # [batch_size * max_length, hidden_size]\n",
    "    seq_embed = tf.contrib.layers.fully_connected(seq_flat, hidden_size)\n",
    "    seq_embed = tf.reshape(seq_embed, [-1, input_1_frames, hidden_size])\n",
    "    \n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=x_lstm_keep_prob)\n",
    "    init_state = cell.zero_state(tf.shape(x_lstm)[0], dtype=tf.float32)\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell, x_lstm, sequence_length=x_lstm_seq_length,\n",
    "                                        initial_state=init_state, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    batch_range = tf.range(tf.shape(outputs)[0])\n",
    "    last_index = x_lstm_seq_length - 1\n",
    "    indices = tf.stack([batch_range, last_index], axis=1)\n",
    "    last = tf.gather_nd(outputs, indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('fusion_layer') as scope:\n",
    "\n",
    "        lstm_output_fc = tf.layers.dense(inputs=last, units=512, activation=tf.nn.relu)\n",
    "\n",
    "        x_fusion_fc = tf.layers.dense(inputs=x_fusion, units=64, activation=tf.nn.relu)\n",
    "\n",
    "        fused_tensor = tf.concat(axis=1,values=[lstm_output_fc, x_fusion_fc])\n",
    "\n",
    "        last_layer = tf.layers.dense(inputs=fused_tensor, units=32, activation=tf.nn.relu) # ReLU\n",
    "\n",
    "        y_pred = tf.layers.dense(inputs=last_layer, units=1, activation=tf.nn.softmax, name='regression_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm, x_fusion, y, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "for batch in range(eopch_num):\n",
    "    \n",
    "    X_train_lstm, X_train_fusion, y_train = data_pipeline(training_df, recmodel.user_latent_traninig, recmodel.visual_features, batch_size_)   \n",
    "    batch_lstm_xs = np.array(X_train_lstm[batch * batch_size_: (batch + 1) * batch_size_], dtype=float)\n",
    "    batch_train_xs = np.array(X_train_fusion[batch * batch_size_: (batch + 1) * batch_size_], dtype=float)\n",
    "    batch_ys = np.array(y_train[batch * batch_size_: (batch + 1) * batch_size_], dtype=float).reshape(batch_size_,1)\n",
    "    \n",
    "    print((batch_lstm_xs.dtype))\n",
    "    print((batch_train_xs.dtype))\n",
    "    print((batch_ys.dtype))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch_lstm_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_train_xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2048]*batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'main_parameters/keep_prob:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lstm_keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - RMSE: 1.6875\n",
      "Epoch 101 - RMSE: 1.75\n",
      "Epoch 201 - RMSE: 1.6875\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for batch in range(eopch_num):\n",
    "        X_train_lstm, X_train_fusion, y_train = data_pipeline(training_df, recmodel.user_latent_traninig, recmodel.visual_features, batch_size_)  \n",
    "        #print(len(y_train[batch * batch_size_: (batch + 1) * batch_size_]))\n",
    "        batch_lstm_xs = np.array(X_train_lstm, dtype=float)\n",
    "        batch_train_xs = np.array(X_train_fusion, dtype=float)\n",
    "        batch_ys = np.array(y_train, dtype=float).reshape(batch_size_,1)\n",
    "        batch_seq_lenth_xs = np.array([2048]*batch_size)\n",
    "        \n",
    "        #print(\"{} {} {} {}\".format(batch_lstm_xs.shape, batch_train_xs.shape,batch_ys.shape,batch_seq_lenth_xs.shape))\n",
    "        \n",
    "\n",
    "        _, batch_loss = sess.run(\n",
    "            [optimizer, cost],\n",
    "            feed_dict={x_lstm: batch_lstm_xs,\n",
    "                       x_lstm_seq_length:batch_seq_lenth_xs,\n",
    "                       x_lstm_keep_prob:0.5,\n",
    "                       x_fusion: batch_train_xs,\n",
    "                       y: batch_ys})\n",
    "\n",
    "        if batch%100==0:\n",
    "            #msg = \"Epoch {} - Training Batch Loss: {:.4f}\"\n",
    "            #print(msg.format((batch+1), batch_loss))\n",
    "            \n",
    "            X_train_lstm, X_train_fusion, y_train = data_pipeline(training_df, recmodel.user_latent_traninig, recmodel.visual_features, 1000)  \n",
    "            #print(len(y_train[batch * batch_size_: (batch + 1) * batch_size_]))\n",
    "            batch_lstm_xs = np.array(X_train_lstm, dtype=float)\n",
    "            batch_train_xs = np.array(X_train_fusion, dtype=float)\n",
    "            batch_ys = np.array(y_train, dtype=float).reshape(batch_size_,1)\n",
    "            batch_seq_lenth_xs = np.array([2048]*batch_size)\n",
    "\n",
    "            #print(\"{} {} {} {}\".format(batch_lstm_xs.shape, batch_train_xs.shape,batch_ys.shape,batch_seq_lenth_xs.shape))\n",
    "\n",
    "\n",
    "            predictions = sess.run(\n",
    "                [y_pred],\n",
    "                feed_dict={x_lstm: batch_lstm_xs,\n",
    "                           x_lstm_seq_length:batch_seq_lenth_xs,\n",
    "                           x_lstm_keep_prob:0.5,\n",
    "                           x_fusion: batch_train_xs,\n",
    "                           y: batch_ys})\n",
    "            \n",
    "            RMSE = (np.square(batch_ys - predictions)).mean()\n",
    "            \n",
    "            #msg = \"Epoch {} - Training Batch Loss: {:.4f}\"\n",
    "            #print(msg.format((batch+1), batch_loss))\n",
    "            \n",
    "            msg = \"Epoch {} - RMSE: {}\"\n",
    "            print(msg.format((batch+1), RMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'time.time'; 'time' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-64932817fac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'time.time'; 'time' is not a package"
     ]
    }
   ],
   "source": [
    "import time.time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot infer num from shape (?, 30, 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a62b8bda1264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm_layer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstate_per_layer_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrnn_tuple_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMStateTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_per_layer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_per_layer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# create an LSTM cell to be unrolled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforget_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(value, num, axis, name)\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot infer num from shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot infer num from shape (?, 30, 2048)"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('lstm_layer') as scope:\n",
    "    state_per_layer_list = tf.unstack(x_lstm, axis=0)\n",
    "    rnn_tuple_state = tuple([tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1]) for idx in range(num_layers)])\n",
    "    # create an LSTM cell to be unrolled\n",
    "    cell = tf.contrib.rnn.LSTMCell(hidden_size, forget_bias=1.0)\n",
    "    \n",
    "    # add a dropout wrapper if training\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([cell for _ in range(num_layers)], state_is_tuple=True)\n",
    "\n",
    "    # cell = tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True)\n",
    "    # cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n",
    "\n",
    "    output, state = tf.nn.dynamic_rnn(cell, x_lstm, dtype=tf.float32, initial_state=rnn_tuple_state)\n",
    "    # reshape to (batch_size * num_steps, hidden_size)\n",
    "    lstm_output = tf.reshape(output, [-1, hidden_size])\n",
    "\n",
    "    lstm_output = lstm_output/tf.reduce_max(tf.abs(lstm_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'lstm_layer/strided_slice:0' shape=(2048,) dtype=float32>, h=<tf.Tensor 'lstm_layer/strided_slice_1:0' shape=(2048,) dtype=float32>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_tuple_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'lstm_layer/strided_slice_2:0' shape=(2048,) dtype=float32>, h=<tf.Tensor 'lstm_layer/strided_slice_3:0' shape=(2048,) dtype=float32>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_tuple_state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Neural Network\n",
    "with tf.name_scope(\"rnn\"):\n",
    "    cell = self._get_cell(hidden_size, cell_type)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=self.dropout_keep_prob)\n",
    "    all_outputs, _ = tf.nn.dynamic_rnn(cell=cell,\n",
    "                                       inputs=self.embedded_chars,\n",
    "                                       sequence_length=text_length,\n",
    "                                       dtype=tf.float32)\n",
    "    self.h_outputs = self.last_relevant(all_outputs, text_length)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
